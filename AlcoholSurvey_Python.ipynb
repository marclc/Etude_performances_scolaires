{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travail réalisé par Marc le Chevoir, Claire Espérou et Adrien Schaffner, encadrés par Philippe Besse.\n",
    "\n",
    "\n",
    "# Etude du jeu de données \"Maths\" ou \"Portugais\" avec Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Importation des données\n",
    "\n",
    "Choisir le jeu de données : soit l'évaluation en Maths, soit en Portugais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data=pd.read_csv(\"./student/student-mat.csv\",sep=\";\",header=0)\n",
    "#Data=pd.read_csv(\"./student/student-por.csv\",sep=\";\",header=0)\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,np.shape(Data)[0]):\n",
    "    if (Data[\"G3\"][i]==0) :\n",
    "        Data = Data.drop(i, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications pour variables qualitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Variables_descri=pd.get_dummies(Data[[\"school\",\"sex\",\"address\",\"famsize\",\"Pstatus\",\"Mjob\",\"Fjob\",\"reason\",\"guardian\",\"schoolsup\",\"famsup\",\"paid\",\"activities\",\"nursery\",\"higher\",\"internet\",\"romantic\"]])\n",
    "Variables_numeric = Data[[\"age\",\"Medu\",\"Fedu\",\"traveltime\",\"studytime\",\"failures\",\"famrel\",\"freetime\",\"goout\",\"Dalc\",\"Walc\",\"health\",\"absences\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_num = pd.concat([Variables_descri,Variables_numeric],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Séparation des données en un échantillon \"Apprentissage\" et un \"Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = Data[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train,X_test,Y_train,Y_test=train_test_split(Data_num,Y,test_size=int(0.2*np.shape(Data_num)[0]),random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Modèle linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Construction d'un modèle sans optimisation de paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = linear_model.Lasso()\n",
    "reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_RL=reg.predict(X_test)\n",
    "print(\"MSE=\",mean_squared_error(Y_test,prev_RL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(prev_RL,Y_test-prev_RL,\"o\")\n",
    "plt.xlabel(u\"Prédites\")\n",
    "plt.ylabel(u\"Résidus\")\n",
    "plt.hlines(0,5,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ceofs_var = reg.fit(X_train, Y_train).coef_\n",
    "for i in range (0, 56):\n",
    "    if (abs(ceofs_var[i]) != 0):\n",
    "        print(X_train.columns[i]+\"____\"+str(ceofs_var[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à améliorer le modèle en optimisant le paramètre alpha de la méthode lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Optmisation du modèle linéaire en optimisant le paramètre alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1=datetime.datetime.now()\n",
    "\n",
    "# grille de valeurs du paramètre alpha à optimiser\n",
    "param=[{\"alpha\":[0.01,0.05,0.1,0.15,0.2,0.3,0.4,0.5,1]}]\n",
    "reg = GridSearchCV(linear_model.Lasso(), param,cv=5,n_jobs=-1)\n",
    "regOpt=reg.fit(X_train, Y_train)\n",
    "\n",
    "# paramètre optimal\n",
    "regOpt.best_params_[\"alpha\"]\n",
    "print(\"Meilleur R2 = %f, Meilleur paramètre = %s\" % (regOpt.best_score_,regOpt.best_params_))\n",
    "\n",
    "\n",
    "t2=datetime.datetime.now()\n",
    "print((t2.second+t2.microsecond*0.000001) - (t1.second+t1.microsecond*0.000001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Prévision sur l'échantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prev_RL=regOpt.predict(X_test)\n",
    "print(\"MSE=\",mean_squared_error(Y_test,prev_RL))\n",
    "prev_RL #Notes prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(prev_RL,Y_test-prev_RL,\"o\")\n",
    "plt.xlabel(u\"Prédites\")\n",
    "plt.ylabel(u\"Résidus\")\n",
    "plt.hlines(0,5,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(prev_RL)\n",
    "for i in range (0, np.size(prev_RL)):\n",
    "    prev_RL[i] = round(prev_RL[i]) #On arrondi les valeurs prédites pour les comparer\n",
    "                            # plus facilement aux valeurs réelles\n",
    "print(prev_RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table=pd.crosstab(prev_RL,Y_test)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"MSE=\",mean_squared_error(Y_test,prev_RL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 - Calcul du temps moyen d'exécution de l'algortihme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_tot = []\n",
    "for i in range(0,50):\n",
    "    t1=datetime.datetime.now()\n",
    "    # grille de valeurs du paramètre alpha à optimiser\n",
    "    param=[{\"alpha\":[0.01,0.05,0.1,0.15,0.2,0.3,0.4,0.5,1]}]\n",
    "    reg = GridSearchCV(linear_model.Lasso(), param,cv=5,n_jobs=-1)\n",
    "    regOpt=reg.fit(X_train, Y_train)\n",
    "    # paramètre optimal\n",
    "    regOpt.best_params_[\"alpha\"]\n",
    "    #print(\"Meilleur R2 = %f, Meilleur paramètre = %s\" % (regOpt.best_score_,regOpt.best_params_))\n",
    "\n",
    "\n",
    "    t2=datetime.datetime.now()\n",
    "    t_tot.append((t2.second+t2.microsecond*0.000001) - (t1.second+t1.microsecond*0.000001))\n",
    "#print(t_tot)\n",
    "#pint(np.mean(t_tot))\n",
    "\n",
    "t_b=[]\n",
    "for i in range(0,np.size(t_tot)):\n",
    "    if (t_tot[i] > 0 ):\n",
    "        t_b.append(t_tot[i])\n",
    "        \n",
    "print(t_b)\n",
    "print(np.mean(t_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 - Analyse des variables retenues sur 25 modèles obtenus par validation croisée de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "check_random_state(13)\n",
    "\n",
    "reg = linear_model.Lasso()\n",
    "\n",
    "# Nombre d'itérations\n",
    "B=25\n",
    "\n",
    "# définition des grilles de paramètres\n",
    "listMethGrid=[\n",
    "    [reg,{\"alpha\":[0.01,0.05,0.1,0.15,0.2]}],\n",
    "    ]\n",
    "# Initialisation à 0 des erreurs pour chaque méthode (colonne) et chaque itération (ligne)\n",
    "arrayErreur=np.empty((B,1)) \n",
    "arrayMSE=np.empty((B,1)) \n",
    "arrayParam=[] #sauvegarde des coefficients des variablesde chaque test\n",
    "for i in range(B):   # itérations sur B échantillons test\n",
    "    # extraction apprentissage et test\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(Data_num,Data[\"G3\"],test_size=int(0.2*np.shape(Data_num)[0]))\n",
    "    # optimisation de chaque méthode et calcul de l'erreur sur le test\n",
    "    for j,(method, grid_list) in enumerate(listMethGrid):\n",
    "        methodGrid=GridSearchCV(method,grid_list,cv=5,n_jobs=-1).fit(X_train, Y_train)\n",
    "        methodOpt = methodGrid.best_estimator_\n",
    "        methFit=methodOpt.fit(X_train, Y_train)\n",
    "        methPred = methodOpt.predict(X_test)\n",
    "        arrayParam.append(methodOpt.fit(X_train, Y_train).coef_)\n",
    "        arrayMSE[i,j]=mean_squared_error(Y_test,np.transpose(methPred))\n",
    "        arrayErreur[i,j]=1-methFit.score(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range (0,25):\n",
    "    for i in range (0, np.size(X_train.columns)):\n",
    "        if (abs(arrayParam[k][i]) != 0):\n",
    "            print(X_train.columns[i]+\"____\"+str(arrayParam[k][i]))\n",
    "    print('******************************')\n",
    "    print('******************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Arbre de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Construction du modèle avec optimisation de la profondeur de l'arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1=datetime.datetime.now()\n",
    "\n",
    "# Optimisation de la profondeur de l'arbre\n",
    "param=[{\"max_depth\":list(range(2,10))}]\n",
    "tree= GridSearchCV(DecisionTreeRegressor(),param,cv=10,n_jobs=-1)\n",
    "treeOpt=tree.fit(X_train, Y_train)\n",
    "\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - treeOpt.best_score_,treeOpt.best_params_))\n",
    "\n",
    "\n",
    "t2=datetime.datetime.now()\n",
    "print((t2.second+t2.microsecond*0.000001) - (t1.second+t1.microsecond*0.000001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimation de l'erreur de prévision\n",
    "1-treeOpt.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Préivsion sur l'échantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prévision de l'échantillon test\n",
    "prev_DT = treeOpt.predict(X_test)\n",
    "\n",
    "#print(prev_DT)\n",
    "\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(prev_DT,Y_test)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"MSE=\",mean_squared_error(Y_test,prev_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - Aperçu graphique de l'arbre modélisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus\n",
    "treeG=DecisionTreeRegressor(max_depth=treeOpt.best_params_['max_depth'])\n",
    "treeG.fit(X_train,Y_train)\n",
    "dot_data = StringIO() \n",
    "export_graphviz(treeG, out_file=dot_data) \n",
    "graph=pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "\n",
    "graph.write_png(\"treeOpt.png\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='treeOpt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Data_num.columns[48])\n",
    "print(Data_num.columns[28])\n",
    "print(Data_num.columns[53])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 - Calcul du temps moyen d'exécution de l'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_tot = np.zeros(50)\n",
    "for i in range(0,50):\n",
    "    t1=datetime.datetime.now()\n",
    "    # Optimisation de la profondeur de l'arbre\n",
    "    param=[{\"max_depth\":list(range(2,10))}]\n",
    "    tree= GridSearchCV(DecisionTreeRegressor(),param,cv=10,n_jobs=-1)\n",
    "    treeOpt=tree.fit(X_train, Y_train)\n",
    "    # paramètre optimal\n",
    "    #print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - treeOpt.best_score_,treeOpt.best_params_))\n",
    "\n",
    "\n",
    "    t2=datetime.datetime.now()\n",
    "    t_tot[i]=((t2.second+t2.microsecond*0.000001) - (t1.second+t1.microsecond*0.000001))\n",
    "print(t_tot)\n",
    "print(np.mean(t_tot))\n",
    "\n",
    "t_b=[]\n",
    "for i in range(0,np.size(t_tot)):\n",
    "    if (t_tot[i] > 0 ):\n",
    "        t_b.append(t_tot[i])\n",
    "        \n",
    "print(t_b)\n",
    "print(np.mean(t_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 - Analyse des variables retenues sur 25 modèles obtenus par validation croisée de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "import time\n",
    "check_random_state(13)\n",
    "# définition des estimateurs\n",
    "\n",
    "arbre = DecisionTreeRegressor()\n",
    "\n",
    "# Nombre d'itérations\n",
    "B=25\n",
    "\n",
    "# définition des grilles de paramètres\n",
    "listMethGrid=[\n",
    "    [arbre,{\"max_depth\":[2,3,4,5,6,7,8,9,10]}]#,\n",
    "    ]\n",
    "\n",
    "# Initialisation à 0 des erreurs pour chaque méthode (colonne) et chaque itération (ligne)\n",
    "arrayErreur=np.empty((B,5)) \n",
    "arrayMSE=np.empty((B,5)) \n",
    "for i in range(B):   # itérations sur B échantillons test\n",
    "    # extraction apprentissage et test\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(Data_num,Data[\"G3\"],test_size=int(0.2*np.shape(Data_num)[0]))\n",
    "    # optimisation de chaque méthode et calcul de l'erreur sur le test\n",
    "    for j,(method, grid_list) in enumerate(listMethGrid):\n",
    "        methodGrid=GridSearchCV(method,grid_list,cv=5,n_jobs=-1).fit(X_train, Y_train)\n",
    "        methodOpt = methodGrid.best_estimator_\n",
    "        methFit=methodOpt.fit(X_train, Y_train)\n",
    "        methPred = methodOpt.predict(X_test)\n",
    "        arrayMSE[i,j]=mean_squared_error(Y_test,np.transpose(methPred))\n",
    "        arrayErreur[i,j]=1-methFit.score(X_test,Y_test)\n",
    "        for i in range (0, np.size(X_train.columns)):\n",
    "            if (abs(methFit.feature_importances_[i]) != 0):\n",
    "                print(X_train.columns[i]+\"____\"+str(methFit.feature_importances_[i]))\n",
    "        print('******************************')\n",
    "        print('******************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 - Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation par validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1=datetime.datetime.now()\n",
    "\n",
    "param=[{\"max_features\":list(range(1,10,1))}]\n",
    "\n",
    "rf= GridSearchCV(\n",
    "    RandomForestRegressor(n_estimators=100),\n",
    "    param,cv=5,n_jobs=-1)\n",
    "\n",
    "rfOpt=rf.fit(X_train, Y_train)\n",
    "\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f\" % (1. - rfOpt.best_score_,))\n",
    "print(\"Meilleur paramètre = %s\" % (rfOpt.best_params_))\n",
    "\n",
    "t2=datetime.datetime.now()\n",
    "print((t2.second+t2.microsecond*0.000001) - (t1.second+t1.microsecond*0.000001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# définition des paramètres\n",
    "forest = RandomForestRegressor(n_estimators=500, \n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1, \n",
    "    max_features=rfOpt.best_params_[\"max_features\"], \n",
    "    max_leaf_nodes=None,\n",
    "    bootstrap=True, oob_score=True)\n",
    "\n",
    "# apprentissage\n",
    "rfFit = forest.fit(X_train,Y_train)\n",
    "print(1-rfFit.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# erreur de prévision sur le test\n",
    "1-rfFit.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 - Prévision sur l'échantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prévision\n",
    "prev_RF = rfFit.predict(X_test)\n",
    "print(prev_RF)\n",
    "\n",
    "for i in range (0, np.size(prev_RF)):\n",
    "    prev_RF[i] = round(prev_RF[i]) #On arrondi les valeurs prédites pour les comparer\n",
    "                            # plus facilement aux valeurs réelles\n",
    "print(prev_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# matrice de confusion\n",
    "table=pd.crosstab(prev_RF,Y_test)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"MSE=\",mean_squared_error(Y_test,prev_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 - Importance des variables dans le modèle créé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importance décroissante des variables\n",
    "importances = rfFit.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(Data_num.columns[indices[f]], importances[indices[f]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 - Calcul du temps moyen d'exécution de l'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_tot = np.zeros(50)\n",
    "for i in range(0,50):\n",
    "    t1=datetime.datetime.now()\n",
    "\n",
    "    param=[{\"max_features\":list(range(1,10,1))}]\n",
    "\n",
    "    rf= GridSearchCV(\n",
    "        RandomForestRegressor(n_estimators=100),\n",
    "        param,cv=5,n_jobs=-1)\n",
    "\n",
    "    rfOpt=rf.fit(X_train, Y_train)\n",
    "\n",
    "    # paramètre optimal\n",
    "    #print(\"Meilleur score = %f\" % (1. - rfOpt.best_score_,))\n",
    "    #print(\"Meilleur paramètre = %s\" % (rfOpt.best_params_))\n",
    "    \n",
    "    t2=datetime.datetime.now()\n",
    "    t_tot[i]=((t2.second+t2.microsecond*0.000001) - (t1.second+t1.microsecond*0.000001))\n",
    "#print(t_tot)\n",
    "#print(np.mean(t_tot))\n",
    "\n",
    "t_b=[]\n",
    "\n",
    "for i in range(0,np.size(t_tot)):\n",
    "    if (t_tot[i] > 0 ):\n",
    "        t_b.append(t_tot[i])\n",
    "        \n",
    "print(t_b)\n",
    "print(np.mean(t_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6 - Algorithme de boosting : GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 - Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "t1=datetime.datetime.now()\n",
    "\n",
    "# Optimisation de deux paramètres\n",
    "paramGrid = [\n",
    "  {'n_estimators': list(range(20,201,20)), 'learning_rate': [0.04,0.06,0.08,0.1,0.12,0.14]}\n",
    " ]\n",
    "gbmC= GridSearchCV(GradientBoostingRegressor(),paramGrid,cv=5,n_jobs=-1)\n",
    "gbmOpt=gbmC.fit(X_train, Y_train)\n",
    "\n",
    "# paramètre optimal, \n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - gbmOpt.best_score_,gbmOpt.best_params_))\n",
    "\n",
    "\n",
    "t2=datetime.datetime.now()\n",
    "print((t2.second+t2.microsecond*0.000001) - (t1.second+t1.microsecond*0.000001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 - Prévision sur l'échantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prévision de l'échantillon test\n",
    "yChap = gbmOpt.predict(X_test)\n",
    "\n",
    "\n",
    "#print(yChap)\n",
    "for i in range (0, np.size(yChap)):\n",
    "    yChap[i] = round(yChap[i]) #On arrondi les valeurs prédites pour les comparer\n",
    "                            # plus facilement aux valeurs réelles\n",
    "print(yChap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# matrice de confusion\n",
    "table=pd.crosstab(yChap,Y_test)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Erreur de prévision sur le test\n",
    "print(\"Erreur de test gbm opt = %f\" % (1-gbmOpt.score(X_test,Y_test)))\n",
    "print(\"MSE=\",mean_squared_error(Y_test,yChap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 - Calcul du temps moyen d'exécution de l'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "t_tot = np.zeros(50)\n",
    "for i in range(0,50):\n",
    "    t1=datetime.datetime.now()\n",
    "\n",
    "    # Optimisation de deux paramètres\n",
    "    paramGrid = [\n",
    "      {'n_estimators': list(range(20,201,20)), 'learning_rate': [0.04,0.06,0.08,0.1,0.12,0.14]}\n",
    "     ]\n",
    "    gbmC= GridSearchCV(GradientBoostingRegressor(),paramGrid,cv=5,n_jobs=-1)\n",
    "    gbmOpt=gbmC.fit(X_train, Y_train)\n",
    "    \n",
    "    # paramètre optimal, \n",
    "    #print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - gbmOpt.best_score_,gbmOpt.best_params_))\n",
    "\n",
    "\n",
    "    t2=datetime.datetime.now()\n",
    "    t_tot[i]=((t2.second+t2.microsecond*0.000001) - (t1.second+t1.microsecond*0.000001))\n",
    "#print(t_tot)\n",
    "#print(np.mean(t_tot))\n",
    "\n",
    "t_b=[]\n",
    "\n",
    "for i in range(0,np.size(t_tot)):\n",
    "    if (t_tot[i] > 0 ):\n",
    "        t_b.append(t_tot[i])\n",
    "        \n",
    "print(t_b)\n",
    "print(np.mean(t_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Algorithme de boosting : XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 - Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "t1=datetime.datetime.now()\n",
    "\n",
    "paramGrid = [\n",
    "  {'n_estimators': list(range(10,201,10)), 'learning_rate': [0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1]}\n",
    " ]\n",
    "gbmC= GridSearchCV(xgb.XGBRegressor(),paramGrid,cv=5,n_jobs=-1)\n",
    "gbmOpt=gbmC.fit(X_train, Y_train)\n",
    "# paramètre optimal, \n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - gbmOpt.best_score_,gbmOpt.best_params_))\n",
    "\n",
    "t2=datetime.datetime.now()\n",
    "print((t2.minute*60+t2.second+t2.microsecond*0.000001) - (t1.minute*60+t1.second+t1.microsecond*0.000001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 - Prévision sur l'échantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_xgb = gbmOpt.predict(X_test)\n",
    "\n",
    "for i in range (0, np.size(pred_xgb)):\n",
    "    pred_xgb[i] = round(pred_xgb[i]) #On arrondi les valeurs prédites pour les comparer\n",
    "                            # plus facilement aux valeurs réelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table=pd.crosstab(pred_xgb,Y_test)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"MSE=\",mean_squared_error(Y_test,np.transpose(pred_xgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 - Calcul du temps moyen d'exécution de l'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "t_tot = np.zeros(50)\n",
    "for i in range(0,50):\n",
    "    print(i)\n",
    "    t1=datetime.datetime.now()\n",
    "    \n",
    "    paramGrid = [\n",
    "      {'n_estimators': list(range(10,201,10)), 'learning_rate': [0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1]}\n",
    "     ]\n",
    "    gbmC= GridSearchCV(xgb.XGBRegressor(),paramGrid,cv=5,n_jobs=-1)\n",
    "    gbmOpt=gbmC.fit(X_train, Y_train)\n",
    "    # paramètre optimal, \n",
    "    #print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - gbmOpt.best_score_,gbmOpt.best_params_))\n",
    "    \n",
    "    t2=datetime.datetime.now()\n",
    "    t_tot[i]=((t2.minute*60+t2.second+t2.microsecond*0.000001) - (t1.minute*60+t1.second+t1.microsecond*0.000001))\n",
    "#print(t_tot)\n",
    "#print(np.mean(t_tot))\n",
    "\n",
    "t_b=[]\n",
    "\n",
    "for i in range(0,np.size(t_tot)):\n",
    "    if (t_tot[i] > 0 ):\n",
    "        t_b.append(t_tot[i])\n",
    "        \n",
    "print(t_b)\n",
    "print(np.mean(t_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Validation croisée de Monte Carlo sur tous les modèles pour comparer les erreurs de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "import xgboost as xgb\n",
    "import time\n",
    "check_random_state(13)\n",
    "# définition des estimateurs\n",
    "\n",
    "reg   = linear_model.Lasso()\n",
    "arbre = DecisionTreeRegressor()\n",
    "rf    = RandomForestRegressor(n_estimators=200)\n",
    "gbm   = GradientBoostingRegressor()\n",
    "xgb   = xgb.XGBRegressor()\n",
    "\n",
    "# Nombre d'itérations\n",
    "B=50\n",
    "\n",
    "# définition des grilles de paramètres\n",
    "listMethGrid=[\n",
    "    [reg,{\"alpha\":[0.01,0.05,0.1,0.15,0.2]}],\n",
    "    [arbre,{\"max_depth\":[2,3,4,5,6,7,8,9,10]}],\n",
    "    [rf,{\"max_features\":[2,3,4,5,6,7,8,9,10]}],\n",
    "    [gbm,{'n_estimators': list(range(50,301,20)), 'learning_rate': [0.04,0.06,0.08,0.1,0.12,0.14,0.16]}],\n",
    "    [xgb,{'n_estimators': list(range(10,201,10)), 'learning_rate': [0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1]}]\n",
    "    ]\n",
    "\n",
    "# Initialisation à 0 des erreurs pour chaque méthode (colonne) et chaque itération (ligne)\n",
    "arrayErreur=np.empty((B,5)) \n",
    "arrayMSE=np.empty((B,5)) \n",
    "for i in range(B):   # itérations sur B échantillons test\n",
    "    # extraction apprentissage et test\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(Data_num,Data[\"G3\"],test_size=int(0.2*np.shape(Data_num)[0]))\n",
    "    # optimisation de chaque méthode et calcul de l'erreur sur le test\n",
    "    for j,(method, grid_list) in enumerate(listMethGrid):\n",
    "        methodGrid=GridSearchCV(method,grid_list,cv=5,n_jobs=-1).fit(X_train, Y_train)\n",
    "        methodOpt = methodGrid.best_estimator_\n",
    "        methFit=methodOpt.fit(X_train, Y_train)\n",
    "        methPred = methodOpt.predict(X_test)\n",
    "        arrayMSE[i,j]=mean_squared_error(Y_test,np.transpose(methPred))\n",
    "        arrayErreur[i,j]=1-methFit.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeErreur=pd.DataFrame(arrayErreur,columns=[\"reg\",\"Arbre\",\"RF\",\"GBM\",\"XGB\"])\n",
    "dataframeMSE=pd.DataFrame(arrayMSE,columns=[\"reg\",\"Arbre\",\"RF\",\"GBM\",\"XGB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution des erreurs\n",
    "dataframeErreur[[\"reg\",\"Arbre\",\"RF\",\"GBM\",\"XGB\"]].boxplot(return_type='dict')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframeMSE[[\"reg\",\"Arbre\",\"RF\",\"GBM\",\"XGB\"]].boxplot(return_type='dict')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.mean(dataframeMSE[\"reg\"]))\n",
    "print(np.mean(dataframeMSE[\"Arbre\"]))\n",
    "print(np.mean(dataframeMSE[\"RF\"]))\n",
    "print(np.mean(dataframeMSE[\"GBM\"]))\n",
    "print(np.mean(dataframeMSE[\"XGB\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - Comparaison des moyennes des erreurs des différentes méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.f_oneway(arrayErreur[:,0],arrayErreur[:,1],arrayErreur[:,2],arrayErreur[:,3],arrayErreur[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En enlevant \"arbre\" qui a une moyenne d'erreur de prédiction clairement différente des autres modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.f_oneway(arrayErreur[:,0],arrayErreur[:,2],arrayErreur[:,3],arrayErreur[:,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
